{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets # For ImageNet (if used)\n",
    "from PIL import Image # For handling image data\n",
    "\n",
    "# 1. Model Definition (Base Architecture - Simplified OverFeat)\n",
    "class OverFeatBase(nn.Module):\n",
    "    def __init__(self, num_classes=1000): #  ImageNet classes by default\n",
    "        super(OverFeatBase, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 1024, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # Adaptive pooling to handle variable input sizes during feature extraction\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))  # Adjust based on your feature extraction point\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        return x\n",
    "\n",
    "# 2. Data Loading and Preprocessing\n",
    "\n",
    "# For ImageNet (if pretraining on ImageNet)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"path/to/imagenet/train\", transform=transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "# 3. Pre-training (Simplified - assuming you train the entire base)\n",
    "overfeat = OverFeatBase(num_classes=1000) # for ImageNet\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "overfeat = overfeat.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(overfeat.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1) # Step decay\n",
    "\n",
    "num_epochs = 90  # Adjust based on needs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = overfeat(images)\n",
    "        outputs = overfeat.classifier(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()  # Update learning rate\n",
    "\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Finished Pre-training\")\n",
    "\n",
    "# 4. Freeze Layers for Feature Extraction\n",
    "\n",
    "for param in overfeat.features.parameters(): # Freeze convolutional layers\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 5. Define Feature Extraction Dataset and New Classifier\n",
    "\n",
    "# Define a dataset for your bird species data (replace with your data loading)\n",
    "class BirdDataset(Dataset): # Example dataset\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "transform_bird = transforms.Compose([ # Transform for new dataset\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224), # Consistent size with OverFeat\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Same as ImageNet\n",
    "])\n",
    "\n",
    "# Create a bird dataset (replace paths and labels)\n",
    "image_paths = [\"path/to/bird1.jpg\", \"path/to/bird2.jpg\", ...]\n",
    "labels = [0, 1, ...]\n",
    "bird_dataset = BirdDataset(image_paths, labels, transform=transform_bird)\n",
    "\n",
    "bird_loader = DataLoader(bird_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 6. New Classifier (replacing fully connected layers from original OverFeat network)\n",
    "\n",
    "num_bird_classes = len(set(labels)) # Number of bird classes in dataset\n",
    "\n",
    "# OverFeat with New Classifier\n",
    "class OverFeatForBirds(nn.Module):\n",
    "    def __init__(self, base_model, num_bird_classes):\n",
    "        super(OverFeatForBirds, self).__init__()\n",
    "        self.features = base_model.features\n",
    "        self.avgpool = base_model.avgpool\n",
    "\n",
    "        # Simplified classifier:\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, num_bird_classes) # Bird class number\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Replace with your number of bird species\n",
    "overfeat_birds = OverFeatForBirds(overfeat, num_bird_classes).to(device) # Bring overfeat network to gpu\n",
    "#7. Training the New Classifier\n",
    "\n",
    "criterion_birds = nn.CrossEntropyLoss()\n",
    "# Only train the new classifier parameters\n",
    "optimizer_birds = optim.SGD(overfeat_birds.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs_birds = 50 # Adjust\n",
    "\n",
    "for epoch in range(num_epochs_birds):\n",
    "    for i, (images, labels) in enumerate(bird_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #Forward pass - notice that it is new overfeat model which has old base layers and new final classifying layer\n",
    "        outputs = overfeat_birds(images) # Run both feature extract + new classifier\n",
    "        loss = criterion_birds(outputs, labels)\n",
    "\n",
    "        # Backward and optimize - only train the new classifier\n",
    "        optimizer_birds.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_birds.step()\n",
    "\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs_birds}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Finished Training New Classifier\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
