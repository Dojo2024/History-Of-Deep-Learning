{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-A Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models  # For datasets and transformations\n",
    "import math  # For Xavier initialization\n",
    "\n",
    "# --- 1. Model Definition (VGG Configuration A) ---\n",
    "\n",
    "class VGG_A(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG_A, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))  # Add adaptive average pooling\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  # Correct the input size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),  # Dropout as specified in VGG paper\n",
    "\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        self._initialize_weights() # call weight initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten the output for the FC layers\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "      for m in self.modules(): # loop over all modules in the network\n",
    "          if isinstance(m, nn.Conv2d):\n",
    "              # Xavier/Glorot initialization for conv layers\n",
    "              nn.init.xavier_uniform_(m.weight)\n",
    "              if m.bias is not None:\n",
    "                  nn.init.constant_(m.bias, 0) # initialize bias to 0 if it exists\n",
    "          elif isinstance(m, nn.Linear):\n",
    "              # Xavier/Glorot initialization for linear layers\n",
    "              nn.init.xavier_uniform_(m.weight)\n",
    "              nn.init.constant_(m.bias, 0) # initialize bias to 0\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. Data Loading and Augmentation ---\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size=256, train_scale=256, val_scale=256, use_multiscale=False):\n",
    "    \"\"\"\n",
    "    Creates training and validation data loaders.\n",
    "\n",
    "    Args:\n",
    "      data_dir: Path to the dataset directory.\n",
    "      batch_size: Batch size for training and validation.\n",
    "      train_scale:  The smaller side of the training images, S (single-scale)\n",
    "                    or a tuple (Smin, Smax) for multi-scale.\n",
    "      val_scale:    The smaller side of the validation images (fixed).\n",
    "      use_multiscale: True for multi-scale training.\n",
    "\n",
    "    Returns:\n",
    "        train_loader, val_loader:  Data loaders for training and validation.\n",
    "    \"\"\"\n",
    "    if use_multiscale:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=(0.5, 1.0)), # Scale jittering\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1), # added color jitter\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet stats\n",
    "        ])\n",
    "    else:\n",
    "        # Single-scale training\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize(train_scale), # resize so the smaller side match to train_scale\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1), # added color jitter\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet stats\n",
    "        ])\n",
    "\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(val_scale),  # Resize so smaller side matches val_scale\n",
    "        transforms.CenterCrop(224),   # Center crop to 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    train_dataset = datasets.ImageFolder(root=f'{data_dir}/train', transform=train_transform)\n",
    "    val_dataset = datasets.ImageFolder(root=f'{data_dir}/val', transform=val_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# --- 3. Training Loop ---\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=74, initial_lr=0.01, device=\"cuda\"):\n",
    "    \"\"\"Trains the VGG model.\n",
    "\n",
    "    Args:\n",
    "        model: The VGG model to train.\n",
    "        train_loader: Training data loader.\n",
    "        val_loader: Validation data loader.\n",
    "        num_epochs: Number of training epochs.\n",
    "        initial_lr: Initial learning rate.\n",
    "        device:  Device to train on (\"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        model: The trained model.  (optional: also return training history)\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device) # move the model to specified device\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "    optimizer = optim.SGD(model.parameters(), lr=initial_lr, momentum=0.9, weight_decay=5e-4) # optimzer\n",
    "    # Learning rate scheduler: Reduce LR by factor of 10 when val accuracy plateaus\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True) # learning rate scheduler\n",
    "\n",
    "\n",
    "    best_val_acc = 0.0  # Keep track of best validation accuracy\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate the loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)  # Accumulate loss\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1) # predicted class is the one with the max value\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item() # compute accuracy\n",
    "\n",
    "            if (i + 1) % 100 == 0:  # Print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)  # Calculate average loss per epoch\n",
    "        train_acc = 100 * correct_train / total_train # Calculate accuracy\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "        # --- Validation Loop ---\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():  # No gradient calculation during validation\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "        # Update learning rate (ReduceLROnPlateau)\n",
    "        scheduler.step(val_acc) # the scheduler reduces the learning rate based on validation accuracy\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_vgg_a.pth') # save the weights of the best model\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. Main Execution ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Hyperparameters & Settings ---\n",
    "    data_dir = 'path/to/your/dataset'  # Replace with your dataset path.  Format: dataset/train, dataset/val\n",
    "    num_classes = 1000  # Number of classes in your dataset (ImageNet = 1000)\n",
    "    batch_size = 256\n",
    "    num_epochs = 74 # VGG paper trained for 74 epochs\n",
    "    initial_lr = 0.01 # VGG used 0.01 initial LR\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # check if GPU is available\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    # --- Data Loaders ---\n",
    "    # Example: Single-scale training (S=256)\n",
    "    train_loader, val_loader = get_data_loaders(data_dir, batch_size=batch_size, train_scale=256, val_scale=256)\n",
    "\n",
    "    # Example: Multi-scale training (S in [256, 512])\n",
    "    # train_loader, val_loader = get_data_loaders(data_dir, batch_size=batch_size, train_scale=(256, 512), val_scale = 256, use_multiscale=True)\n",
    "\n",
    "\n",
    "    # --- Create and Train the Model ---\n",
    "    model = VGG_A(num_classes=num_classes)\n",
    "    trained_model = train_model(model, train_loader, val_loader, num_epochs=num_epochs, initial_lr=initial_lr, device=device)\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-A LRN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# --- 1. Model Definition (VGG A-LRN) ---\n",
    "\n",
    "class VGGA_LRN(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGGA_LRN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # LRN Layer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  #  7x7 comes from 224 input size, 5 maxpool layers (224 / (2^5))\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()  # Custom weight initialization\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1) # or x = x.view(x.size(0), -1)  Flatten before FC layers\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Kaiming He initialization (from He et al., 2015, designed for ReLU)\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)  # Initialize biases to 0\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)  # Normal dist, mean 0, std 0.01\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "# --- 2. Data Loading and Augmentation ---\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size, train_scale=256, val_scale=256,\n",
    "                    multi_scale_training=False, s_min=256, s_max=512):\n",
    "\n",
    "    # Common transformations for both training and validation\n",
    "    common_transforms = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet mean/std\n",
    "    ]\n",
    "\n",
    "    if multi_scale_training:\n",
    "        #Multi-scale Training (Scale Jittering)\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=(s_min/val_scale, s_max/val_scale)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            *common_transforms\n",
    "        ])\n",
    "    else:\n",
    "        # Single Scale Training (Fixed S)\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize(train_scale), # first resize to train_scale\n",
    "            transforms.RandomCrop(224),    # then crop the 224X224 part\n",
    "            transforms.RandomHorizontalFlip(), # Random horizontal flip\n",
    "            *common_transforms\n",
    "        ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(val_scale),  # Resize to validation scale (usually 256)\n",
    "        transforms.CenterCrop(224), # Center Crop to 224X224.  For testing, we would use more crops.\n",
    "        *common_transforms\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    train_dataset = datasets.ImageFolder(root=data_dir + '/train', transform=train_transform)\n",
    "    val_dataset = datasets.ImageFolder(root=data_dir + '/val', transform=val_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# --- 3. Training Function ---\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()   # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation during validation\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "                _, val_preds = torch.max(val_outputs, 1)\n",
    "                val_running_loss += val_loss.item() * val_inputs.size(0)\n",
    "                val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_epoch_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "\n",
    "        # --- Learning Rate Scheduler ---\n",
    "        scheduler.step(val_epoch_acc) #Pass validation accuracy to scheduler.  StepLR expects a \"metric\"\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Time: {epoch_duration:.0f}s\")\n",
    "        print(f\"  Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "        print(f\"  Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        if val_epoch_acc > best_val_acc:\n",
    "            best_val_acc = val_epoch_acc\n",
    "            torch.save(model.state_dict(), 'best_model_vgg_a_lrn.pth')\n",
    "\n",
    "\n",
    "# --- 4. Main Training Loop ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Hyperparameters ---\n",
    "    num_classes = 1000  # ImageNet has 1000 classes\n",
    "    batch_size = 256   # VGG used 256\n",
    "    learning_rate = 0.01 # VGG used 0.01 initially\n",
    "    num_epochs = 74  # VGG trained for about 74 epochs (370K iterations)\n",
    "    momentum = 0.9 # Momentum value\n",
    "    weight_decay = 5e-4  # L2 regularization weight decay\n",
    "\n",
    "    # --- Device Configuration ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- Data Loaders ---\n",
    "    data_dir = 'path/to/imagenet/data' # Replace with your ImageNet data path!\n",
    "    train_loader, val_loader = get_data_loaders(data_dir, batch_size)\n",
    "\n",
    "    # --- Model Instance ---\n",
    "    model = VGGA_LRN(num_classes=num_classes).to(device)\n",
    "\n",
    "    # --- Loss Function ---\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Optimizer ---\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    # --- Learning Rate Scheduler (StepLR) ---\n",
    "    # VGG decreased learning rate by a factor of 10 when validation accuracy stopped improving.\n",
    "    # Use StepLR for simplicity (could also use ReduceLROnPlateau).\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    # --- Train the Model ---\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device)\n",
    "\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-B Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# --- 1. Model Definition (VGG-B Configuration) ---\n",
    "\n",
    "class VGG_B(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG_B, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 5\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))  # Add AdaptiveAvgPool2d\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096), # Corrected input size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        self._initialize_weights() # Call weight initialization\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x) # Use AdaptiveAvgPool2d\n",
    "        x = torch.flatten(x, 1)  # Flatten the output\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Kaiming He initialization (recommended for ReLU)\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # Xavier/Glorot initialization (good for fully connected)\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "# --- 2. Data Loading and Augmentation ---\n",
    "# ImageNet mean and std are standard, even if not strictly from *your* training set.\n",
    "# The goal of normalization is to center your data similarly to how ImageNet was centered.\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size=256, train_scale=256, val_scale=256, num_workers=4):\n",
    "    # Single Scale Training (as in the paper)\n",
    "    train_transform_single = transforms.Compose([\n",
    "        transforms.Resize(train_scale),  # Resize the smaller edge to train_scale\n",
    "        transforms.RandomCrop(224),      # Randomly crop a 224x224 patch\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
    "    ])\n",
    "\n",
    "    # Multi-Scale Training (Scale Jittering)\n",
    "    train_transform_multi = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.25, 1.0)), # Random resized crop\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Validation/Test Transform (keep consistent)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(val_scale),  # Resize\n",
    "        transforms.CenterCrop(224),    # Center crop to 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create datasets (using ImageFolder for folder structure)\n",
    "    train_dataset_single = datasets.ImageFolder(root=data_dir + '/train', transform=train_transform_single)\n",
    "    train_dataset_multi = datasets.ImageFolder(root=data_dir + '/train', transform=train_transform_multi) # Use for multi-scale training\n",
    "    val_dataset = datasets.ImageFolder(root=data_dir + '/val', transform=val_transform)  # Assuming you have a validation set\n",
    "    # test_dataset = datasets.ImageFolder(root=data_dir + '/test', transform=val_transform) # Use if you have a separate test set\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader_single = DataLoader(train_dataset_single, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    train_loader_multi = DataLoader(train_dataset_multi, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) # Multi-scale loader\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    # test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers) #Use if you have a seperate test set\n",
    "\n",
    "    #Return both single scale and multi scale loaders\n",
    "    return train_loader_single, train_loader_multi, val_loader\n",
    "    # return train_loader_single, val_loader  # Return loaders (use train_loader_multi for multi-scale training)\n",
    "\n",
    "# --- 3. Training Loop ---\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=74, device='cuda'):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step() # Step the scheduler after *each* epoch\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model (if it's the best so far)\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. Main Execution ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Hyperparameters (following the paper as closely as possible) ---\n",
    "    num_classes = 1000  # ImageNet classes\n",
    "    batch_size = 256\n",
    "    initial_lr = 0.01  # 10^-2\n",
    "    momentum = 0.9\n",
    "    weight_decay = 5e-4  # 5 * 10^-4\n",
    "    num_epochs = 74      # Total training epochs (VGG trained for ~74 epochs)\n",
    "    train_scale = 256    # Single-scale training: S=256\n",
    "    # train_scale = [256, 512]  # For multi-scale, use a list/tuple\n",
    "    val_scale = 256  # Validation scale (Q) - often same as training scale in single-scale\n",
    "\n",
    "    # --- Device ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- Data Loaders ---\n",
    "    # Replace 'path/to/imagenet' with the actual path to your ImageNet dataset.\n",
    "    #  Make sure your data is organized: path/to/imagenet/train, path/to/imagenet/val\n",
    "    data_dir = 'path/to/imagenet'\n",
    "    train_loader_single, train_loader_multi, val_loader = get_data_loaders(data_dir, batch_size, train_scale, val_scale)\n",
    "\n",
    "\n",
    "    # --- Model Initialization ---\n",
    "    model = VGG_B(num_classes=num_classes).to(device)\n",
    "    #  Pretraining (optional, but recommended for deeper networks)\n",
    "    #   You *could* load weights from a pretrained VGG-A model here if you have it.\n",
    "    #   vgg_a = VGG_A(num_classes=1000)\n",
    "    #   vgg_a.load_state_dict(torch.load('path/to/vgg_a_weights.pth'))\n",
    "    #   # Initialize VGG-B with some layers from VGG-A\n",
    "    #   model.features[:10].load_state_dict(vgg_a.features[:10].state_dict())\n",
    "    #   model.classifier.load_state_dict(vgg_a.classifier.state_dict())\n",
    "\n",
    "    # --- Loss Function ---\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Optimizer ---\n",
    "    # Use SGD with momentum and weight decay, as in the paper\n",
    "    optimizer = optim.SGD(model.parameters(), lr=initial_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    # --- Learning Rate Scheduler ---\n",
    "    # StepLR scheduler (decrease LR by a factor of 10 every time val accuracy plateaus)\n",
    "    # The paper decreased LR 3 times.  Patience=5 means wait 5 epochs of no improvement.\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "    #Alternative learning rate scheduler : StepLR.  Decay LR every 25 epochs by a factor of 0.1 (3 decays total)\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "\n",
    "\n",
    "    # --- Training ---\n",
    "    # Train the model (using single-scale training loader)\n",
    "    #For Single scale\n",
    "    model = train_model(model, train_loader_single, val_loader, criterion, optimizer, scheduler, num_epochs, device)\n",
    "\n",
    "    # --- Save the trained model ---\n",
    "    torch.save(model.state_dict(), 'vgg_b_trained.pth')\n",
    "\n",
    "    #For Multi Scale\n",
    "    # model = train_model(model, train_loader_multi, val_loader, criterion, optimizer, scheduler, num_epochs, device)\n",
    "    # # --- Save the trained model ---\n",
    "    # torch.save(model.state_dict(), 'vgg_b_trained_multi.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-C Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "# --- 1. Model Definition (Configuration C) ---\n",
    "\n",
    "class VGG_C(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VGG_C, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=1, padding=0), # 1x1 convolution\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=1, padding=0), # 1x1 convolution\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 5\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=1, padding=0), # 1x1 convolution\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),  # 7x7 because input is 224x224, and 5 max pooling layers\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()  # Initialize weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature maps\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Kaiming He initialization (He et al., 2015) - better for ReLU\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # Xavier/Glorot initialization (Glorot & Bengio, 2010)\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "# --- 2. Data Augmentation and Loading ---\n",
    "\n",
    "def get_data_loaders(train_batch_size=256, test_batch_size=64, s_train=256, multi_scale=False, s_min=256, s_max=512):\n",
    "    \"\"\"\n",
    "    Gets data loaders with data augmentation for VGG training.\n",
    "\n",
    "    Args:\n",
    "        train_batch_size: Batch size for training.\n",
    "        test_batch_size: Batch size for testing.\n",
    "        s_train:  Single training scale (if multi_scale=False).\n",
    "        multi_scale: Whether to use multi-scale training.\n",
    "        s_min: Minimum scale for multi-scale training.\n",
    "        s_max: Maximum scale for multi-scale training.\n",
    "\n",
    "    Returns:\n",
    "        train_loader: DataLoader for the training set.\n",
    "        val_loader: DataLoader for the validation set.\n",
    "        test_loader: DataLoader for the test set.  (Optional, if you have a separate test set)\n",
    "    \"\"\"\n",
    "\n",
    "    if multi_scale:\n",
    "      # Multi-scale training transforms\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Lambda(lambda x: transforms.RandomResizedCrop(224, scale=(0.08, 1.0))(x) if x.size[0] >= 224 and x.size[1]>=224  else transforms.Resize((224, 224))(x)  ), #  resize smaller images to 224\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # Random RGB color shift\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet stats\n",
    "        ])\n",
    "    else:\n",
    "      # Single-scale training transforms\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize(s_train),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize to 256x256 (as in VGG paper for testing)\n",
    "        transforms.CenterCrop(224),  # Center crop to 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Use CIFAR-10 as an example dataset (easily downloadable).  Replace with your dataset.\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "    val_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=test_transform)  # Use same transform as test for validation\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    # Split train dataset into training and validation (80/20 split).\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader  # Return validation loader as well\n",
    "\n",
    "# --- 3. Training Loop ---\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs=74, device='cuda', initial_lr=0.01):\n",
    "    \"\"\"\n",
    "    Trains the VGG model.\n",
    "\n",
    "    Args:\n",
    "        model: The VGG model to train.\n",
    "        train_loader: DataLoader for the training data.\n",
    "        val_loader: DataLoader for the validation data.\n",
    "        optimizer: The optimizer (e.g., SGD with momentum).\n",
    "        criterion: The loss function (e.g., CrossEntropyLoss).\n",
    "        num_epochs: Number of training epochs.\n",
    "        device: 'cuda' or 'cpu'.\n",
    "        initial_lr: The initial learning rate.\n",
    "    \"\"\"\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True) # Reduce LR on plateau\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # --- Validation Loop ---\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():  # No need to track gradients during validation\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "        scheduler.step(val_loss)  # Update learning rate based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "          best_val_loss = val_loss\n",
    "          torch.save(model.state_dict(), 'best_model.pth') #save checkpoints\n",
    "          print(\"saved the best model\")\n",
    "\n",
    "\n",
    "# --- 4. Main Execution ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 1. Create the model\n",
    "    model = VGG_C(num_classes=10).to(device)  # CIFAR-10 has 10 classes\n",
    "\n",
    "    # 2. Get data loaders (with data augmentation)\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(multi_scale=True)  # Enable multi-scale training\n",
    "\n",
    "\n",
    "    # 3. Define optimizer and loss function\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    # 4. Train the model\n",
    "    train(model, train_loader, val_loader, optimizer, criterion, num_epochs=74, device=device)  # Train for 74 epochs (as in VGG paper)\n",
    "\n",
    "    # 5. (Optional) Load the best saved model and evaluate on the test set.\n",
    "    # best_model = VGG_C(num_classes=10).to(device)\n",
    "    # best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "    # best_model.eval()\n",
    "    # #  ... evaluation code (similar to validation loop) ...\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-E Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "\n",
    "# --- 1. Model Definition (Configuration E - VGG19) ---\n",
    "\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self, num_classes=1000, init_weights=True, pretrain_init=None):\n",
    "        super(VGG19, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 5\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # Adaptive pooling to handle variable sizes\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),  # Dropout after the first two FC layers\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "          if pretrain_init:\n",
    "            self._initialize_weights_from_pretrain(pretrain_init) # init weights from shallower nets\n",
    "          else:\n",
    "            self._initialize_weights() #init weights randomly\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten for FC layers\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Xavier/Glorot initialization\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # Normal initialization for linear layers\n",
    "                nn.init.normal_(m.weight, 0, 0.01)  # Mean 0, std 0.01\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _initialize_weights_from_pretrain(self, pretrained_model_path):\n",
    "       \n",
    "        pretrained_model = torch.load(pretrained_model_path) # load the shallow net.\n",
    "        pretrained_dict = pretrained_model.state_dict()\n",
    "        model_dict = self.state_dict()\n",
    "\n",
    "        # 1. filter out unnecessary keys\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
    "        # 2. overwrite entries in the existing state dict\n",
    "        model_dict.update(pretrained_dict)\n",
    "        # 3. load the new state dict\n",
    "        self.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "# --- 2. Data Loading and Augmentation ---\n",
    "\n",
    "class MultiScaleImageDataset(Dataset):  # Custom dataset for multi-scale training\n",
    "    def __init__(self, image_paths, labels, min_scale=256, max_scale=512, train=True):\n",
    "        super().__init__()\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.train = train\n",
    "\n",
    "        self.base_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "            #^^^ The VGG paper subtracts the mean RGB, calculated from the entire training set.\n",
    "            #^^^ Normalizing with ImageNet stats is standard practice and easier.\n",
    "        ])\n",
    "\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),  # Random crop to 224x224\n",
    "            transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1), # Color jitter\n",
    "            # ^^^ The VGG paper used random RGB shifts. ColorJitter is a common approximation.\n",
    "            self.base_transform  # Apply base transformations (ToTensor, Normalize)\n",
    "        ])\n",
    "\n",
    "        self.test_transform = self.base_transform  # No extra augmentation at test time\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = torchvision.io.read_image(img_path) # Use torchvision.io for faster image loading\n",
    "        img = img / 255.0  # Convert to [0, 1] range\n",
    "\n",
    "        if self.train:\n",
    "          # Multi-scale training: random S from [min_scale, max_scale]\n",
    "          s = random.randint(self.min_scale, self.max_scale) # Isotropic rescaling\n",
    "          # Calculate the scaling factor for both dimensions\n",
    "          scale_factor = s / min(img.shape[-2], img.shape[-1])\n",
    "          new_height, new_width = int(img.shape[-2] * scale_factor), int(img.shape[-1] * scale_factor)\n",
    "          img = transforms.functional.resize(img, (new_height, new_width))\n",
    "          img = self.train_transform(img)\n",
    "        else:\n",
    "          img = self.test_transform(img)\n",
    "\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Training Setup ---\n",
    "\n",
    "def train_vgg19(train_dataset, val_dataset, pretrained_model_path=None, num_epochs=74, batch_size=256, learning_rate=0.01):\n",
    "    \"\"\"Trains a VGG19 model.\n",
    "\n",
    "    Args:\n",
    "        train_dataset: Training dataset.\n",
    "        val_dataset: Validation dataset.\n",
    "        pretrained_model_path: Path to a pretrained VGG-A (or shallower) model, or None for random initialization.\n",
    "        num_epochs: Number of training epochs.\n",
    "        batch_size: Batch size.\n",
    "        learning_rate: Initial learning rate.\n",
    "\n",
    "    Returns:\n",
    "        Trained VGG19 model.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if pretrained_model_path:\n",
    "        model = VGG19(init_weights=True, pretrain_init=pretrained_model_path)\n",
    "        print(f\"Training with pre-trained initialization from {pretrained_model_path}\")\n",
    "    else:\n",
    "        model = VGG19(init_weights=True, pretrain_init=None)\n",
    "        print(\"Training with random initialization\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    # Learning Rate Scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)  #Reduce LR on Plateau\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True) # num_workers and pin_memory for speedup\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % 100 == 0:  # Print every 100 mini-batches\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Batch [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Step the learning rate scheduler based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- 4. Example Usage ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Dummy data for demonstration (replace with your actual dataset loading)\n",
    "    num_samples = 1000\n",
    "    image_paths = [f\"dummy_image_{i}.jpg\" for i in range(num_samples)]  # Replace with real paths\n",
    "    labels = [random.randint(0, 999) for _ in range(num_samples)]  # Replace with real labels\n",
    "\n",
    "    # Create dummy image files\n",
    "    import os\n",
    "    if not os.path.exists(\"dummy_images\"):\n",
    "        os.makedirs(\"dummy_images\")\n",
    "        for path in image_paths:\n",
    "            # Create dummy image, fill it with random data.\n",
    "            dummy_image = torch.rand(3, 256, 256)  # Example size.  Important: it's > 224x224.\n",
    "            torchvision.utils.save_image(dummy_image, os.path.join(\"dummy_images\", path))\n",
    "    image_paths = [os.path.join(\"dummy_images\", path) for path in image_paths]\n",
    "\n",
    "\n",
    "    # Split into training and validation (example)\n",
    "    train_paths = image_paths[:800]\n",
    "    train_labels = labels[:800]\n",
    "    val_paths = image_paths[800:]\n",
    "    val_labels = labels[800:]\n",
    "\n",
    "    train_dataset = MultiScaleImageDataset(train_paths, train_labels, train=True)\n",
    "    val_dataset = MultiScaleImageDataset(val_paths, val_labels, train=False) #train = False\n",
    "\n",
    "\n",
    "    # --- Train the model (with or without pretraining) ---\n",
    "\n",
    "    # Example 1: Train from scratch (random initialization)\n",
    "    #trained_model = train_vgg19(train_dataset, val_dataset, pretrained_model_path=None)\n",
    "\n",
    "    # Example 2: Train with pre-training (using a pre-trained VGG-A, for example)\n",
    "    # You would first need to train a VGG-A model and save its state_dict.\n",
    "    # Let's assume you have a saved VGG-A model at \"vgg_a_model.pth\"\n",
    "\n",
    "    vgg_a = VGG19(init_weights=True) # create a dummy vgga model (as we don't have a vgg a model we will just save the dummy vgga model and use it to initilize the weigths for vgg e model )\n",
    "    # Train VGG-A (replace this with your actual VGG-A training code)\n",
    "    # ... (your VGG-A training code here) ...\n",
    "    torch.save(vgg_a, \"vgg_a_model.pth\") # we are just saving the random initilized model as we don't have vgg a model \n",
    "\n",
    "    # Now, use the pre-trained VGG-A to initialize and train VGG-E.\n",
    "    trained_model = train_vgg19(train_dataset, val_dataset, pretrained_model_path=\"vgg_a_model.pth\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(trained_model, \"vgg19_model.pth\")\n",
    "    print(\"Training complete. Model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
